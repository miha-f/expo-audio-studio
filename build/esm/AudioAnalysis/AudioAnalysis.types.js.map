{"version":3,"file":"AudioAnalysis.types.js","sourceRoot":"","sources":["../../../src/AudioAnalysis/AudioAnalysis.types.ts"],"names":[],"mappings":"AAAA,sEAAsE","sourcesContent":["// packages/expo-audio-stream/src/AudioAnalysis/AudioAnalysis.types.ts\n\nimport { BitDepth, ConsoleLike } from '../ExpoAudioStream.types'\n\n/**\n * Represents the configuration for decoding audio data.\n */\nexport interface DecodingConfig {\n    /** Target sample rate for decoded audio (Android and Web) */\n    targetSampleRate?: number\n    /** Target number of channels (Android and Web) */\n    targetChannels?: number\n    /** Target bit depth (Android and Web) */\n    targetBitDepth?: BitDepth\n    /** Whether to normalize audio levels (Android and Web) */\n    normalizeAudio?: boolean\n}\n\n/**\n * Represents speech-related features extracted from audio.\n */\nexport interface SpeechFeatures {\n    isActive: boolean // Whether speech is detected in this segment\n    speakerId?: number // Optional speaker identification\n    // Could add more speech-related features here like:\n    // confidence: number\n    // language?: string\n    // sentiment?: number\n    // etc.\n}\n\n/**\n * Represents various audio features extracted from an audio signal.\n */\nexport interface AudioFeatures {\n    energy?: number // The infinite integral of the squared signal, representing the overall energy of the audio.\n    mfcc?: number[] // Mel-frequency cepstral coefficients, describing the short-term power spectrum of a sound.\n    rms?: number // Root mean square value, indicating the amplitude of the audio signal.\n    minAmplitude?: number // Minimum amplitude value in the audio signal.\n    maxAmplitude?: number // Maximum amplitude value in the audio signal.\n    zcr?: number // Zero-crossing rate, indicating the rate at which the signal changes sign.\n    spectralCentroid?: number // The center of mass of the spectrum, indicating the brightness of the sound.\n    spectralFlatness?: number // Measure of the flatness of the spectrum, indicating how noise-like the signal is.\n    spectralRolloff?: number // The frequency below which a specified percentage (usually 85%) of the total spectral energy lies.\n    spectralBandwidth?: number // The width of the spectrum, indicating the range of frequencies present.\n    chromagram?: number[] // Chromagram, representing the 12 different pitch classes of the audio.\n    tempo?: number // Estimated tempo of the audio signal, measured in beats per minute (BPM).\n    hnr?: number // Harmonics-to-noise ratio, indicating the proportion of harmonics to noise in the audio signal.\n    melSpectrogram?: number[] // Mel-scaled spectrogram representation of the audio.\n    spectralContrast?: number[] // Spectral contrast features representing the difference between peaks and valleys.\n    tonnetz?: number[] // Tonal network features representing harmonic relationships.\n    pitch?: number // Pitch of the audio signal, measured in Hertz (Hz).\n    crc32?: number // crc32 checksum of the audio signal, used to verify the integrity of the audio.\n}\n\n/**\n * Options to specify which audio features to extract.\n * Note: Advanced features (spectral features, chromagram, pitch, etc.) are experimental,\n * especially during live recording, due to high processing requirements.\n */\nexport interface AudioFeaturesOptions {\n    // Basic features - well optimized\n    energy?: boolean\n    rms?: boolean\n    zcr?: boolean\n\n    // Advanced features - experimental, may impact performance in live recording\n    mfcc?: boolean\n    spectralCentroid?: boolean\n    spectralFlatness?: boolean\n    spectralRolloff?: boolean\n    spectralBandwidth?: boolean\n    chromagram?: boolean\n    tempo?: boolean\n    hnr?: boolean\n    melSpectrogram?: boolean\n    spectralContrast?: boolean\n    tonnetz?: boolean\n    pitch?: boolean\n\n    // Utility\n    crc32?: boolean\n}\n\n/**\n * Represents a single data point in the audio analysis.\n */\nexport interface DataPoint {\n    id: number\n    amplitude: number // Peak amplitude for the segment\n    rms: number // Root mean square value\n    dB: number // dBFS (decibels relative to full scale) computed from RMS value\n    silent: boolean // Always computed\n    features?: AudioFeatures\n    speech?: SpeechFeatures\n    startTime?: number\n    endTime?: number\n    // start / end position in bytes\n    startPosition?: number\n    endPosition?: number\n    // number of audio samples for this point (samples size depends on bit depth)\n    samples?: number\n}\n\n/**\n * Represents the complete data from the audio analysis.\n */\nexport interface AudioAnalysis {\n    segmentDurationMs: number // Duration of each segment in milliseconds\n    durationMs: number // Duration of the audio in milliseconds\n    /**\n     * Bit depth used for audio analysis processing.\n     *\n     * **Important**: This represents the internal processing bit depth, which may differ\n     * from the recording bit depth. Audio is typically converted to 32-bit float for\n     * analysis to ensure precision in calculations, regardless of the original recording format.\n     *\n     * Platform behavior:\n     * - iOS: Always 32 (float processing)\n     * - Android: Always 32 (float processing)\n     * - Web: Always 32 (Web Audio API standard)\n     *\n     * The actual recorded file will maintain the requested bit depth (8, 16, or 32).\n     */\n    bitDepth: number\n    samples: number // Size of the audio in bytes\n    numberOfChannels: number // Number of audio channels\n    sampleRate: number // Sample rate of the audio\n    dataPoints: DataPoint[] // Array of data points from the analysis.\n    amplitudeRange: {\n        min: number\n        max: number\n    }\n    rmsRange: {\n        min: number\n        max: number\n    }\n    extractionTimeMs: number // Time taken to extract/process the analysis in milliseconds\n    // TODO: speaker changes into a broader speech analysis section\n    speechAnalysis?: {\n        speakerChanges: {\n            timestamp: number\n            speakerId: number\n        }[]\n        // Could add more speech analysis data here like:\n        // dominantSpeaker?: number\n        // totalSpeechDuration?: number\n        // speakerStats?: { [speakerId: number]: { duration: number, segments: number } }\n    }\n}\n\n/**\n * Options for specifying a time range within an audio file.\n */\nexport interface AudioRangeOptions {\n    /** Start time in milliseconds */\n    startTimeMs?: number\n    /** End time in milliseconds */\n    endTimeMs?: number\n}\n\n/**\n * Options for generating a quick preview of audio waveform.\n * This is optimized for UI rendering with a specified number of points.\n */\nexport interface PreviewOptions extends AudioRangeOptions {\n    /** URI of the audio file to analyze */\n    fileUri: string\n    /**\n     * Total number of points to generate for the preview.\n     * @default 100\n     */\n    numberOfPoints?: number\n    /**\n     * Optional logger for debugging.\n     */\n    logger?: ConsoleLike\n    /**\n     * Optional configuration for decoding the audio file.\n     * Defaults to:\n     * - targetSampleRate: undefined (keep original)\n     * - targetChannels: undefined (keep original)\n     * - targetBitDepth: 16\n     * - normalizeAudio: false\n     */\n    decodingOptions?: DecodingConfig\n}\n\n/**\n * Options for mel-spectrogram extraction\n *\n * @experimental This feature is experimental and currently only available on Android.\n * The API may change in future versions.\n */\nexport interface ExtractMelSpectrogramOptions {\n    fileUri?: string // Path to audio file\n    arrayBuffer?: ArrayBuffer // Raw audio buffer\n    windowSizeMs: number // Window size in ms (e.g., 25)\n    hopLengthMs: number // Hop length in ms (e.g., 10)\n    nMels: number // Number of mel filters (e.g., 60)\n    fMin?: number // Min frequency (default: 0)\n    fMax?: number // Max frequency (default: sampleRate / 2)\n    windowType?: 'hann' | 'hamming' // Window function (default: 'hann')\n    normalize?: boolean // Mean normalization (default: false)\n    logScale?: boolean // Log scaling of mel energies (default: true)\n    decodingOptions?: DecodingConfig // Audio decoding settings\n    startTimeMs?: number // Optional start time\n    endTimeMs?: number // Optional end time\n    logger?: ConsoleLike\n}\n\n/**\n * Return type for mel spectrogram extraction\n *\n * @experimental This feature is experimental and currently only available on Android.\n * The API may change in future versions.\n */\nexport interface MelSpectrogram {\n    spectrogram: number[][] // 2D array [time][mel]\n    sampleRate: number // Audio sample rate\n    nMels: number // Number of mel filters\n    timeSteps: number // Number of time frames\n    durationMs: number // Audio duration in ms\n}\n"]}